source("~/Downloads/Neurips_Supplement/Functions.R", echo=TRUE)
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
outputMatrix
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
outputMatrix
source("~/Downloads/Neurips_Supplement/Body.R", echo=TRUE)
log((2*5), base = 2)
source("~/.active-rstudio-document", echo=TRUE)
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(n, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(n, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
})
n
?replicate
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(1, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, function(n){
y <- rnorm(n, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, function(n){
y <- rnorm(n, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
})
betas_simulated
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(n, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
})
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(1, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
})
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(sample_size, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
library(tidyverse)
library(cowplot)
set.seed(132)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(sample_size, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
x_scatter_plot <- ggplot(x, aes(x=x1, y=x2)) +
geom_point() +
xlab(bquote(x[1])) +
ylab(bquote(x[2])) +
ggtitle(bquote(x[1] ~ "and" ~ x[2] ~ "with corr." %~~% .(round(cor(x$x1, x$x2), 3)) )) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
beta_hats_cor <- cor(betas_simulated$beta_hat_1, betas_simulated$beta_hat_2)
betas_scatter_plot <- ggplot(betas_simulated, aes(x=beta_hat_1, y=beta_hat_2)) +
geom_point() +
theme_bw() +
xlab(bquote(hat(beta)[1])) +
ylab(bquote(hat(beta)[2])) +
ggtitle(bquote(hat(beta)[1] ~ "and" ~ hat(beta)[2] ~ "with corr."  %~~% .(round(beta_hats_cor, 3)))) +
geom_point(data=data.frame(beta1 = betas_true[2], beta2=betas_true[3]), mapping=aes(x=beta1, y=beta2), col="red") +
theme(plot.title = element_text(hjust = 0.5))
betas_scatter_plot
library(tidyverse)
library(cowplot)
set.seed(961)
sample_size <- 100
error_variance <- 1
betas_true <- 0:2
x_cov_mtx <- matrix(c(1.25, 0.75, 0.75, 1.25), 2, 2, TRUE)
# simulate x_1, x_2 from a bivariate normal and prepend intercept
x <- cbind(1, MASS::mvrnorm(sample_size, c(0,0), x_cov_mtx))
expectation_of_y <- as.numeric(x %*% betas_true)  # keeping x as a matrix for this step
x <- tibble(intercept=x[,1], x1=x[,2], x2=x[,3])
num_simulations <- 250
betas_simulated <- replicate(num_simulations, {
y <- rnorm(sample_size, expectation_of_y, sqrt(error_variance))
coef(lm(y~.-1, data=x))
}) %>%
t() %>%
as_tibble() %>%
rename(beta_hat_0="intercept", beta_hat_1="x1", beta_hat_2="x2")
x_scatter_plot <- ggplot(x, aes(x=x1, y=x2)) +
geom_point() +
xlab(bquote(x[1])) +
ylab(bquote(x[2])) +
ggtitle(bquote(x[1] ~ "and" ~ x[2] ~ "with corr." %~~% .(round(cor(x$x1, x$x2), 3)) )) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
beta_hats_cor <- cor(betas_simulated$beta_hat_1, betas_simulated$beta_hat_2)
betas_scatter_plot <- ggplot(betas_simulated, aes(x=beta_hat_1, y=beta_hat_2)) +
geom_point() +
theme_bw() +
xlab(bquote(hat(beta)[1])) +
ylab(bquote(hat(beta)[2])) +
ggtitle(bquote(hat(beta)[1] ~ "and" ~ hat(beta)[2] ~ "with corr."  %~~% .(round(beta_hats_cor, 3)))) +
geom_point(data=data.frame(beta1 = betas_true[2], beta2=betas_true[3]), mapping=aes(x=beta1, y=beta2), col="red") +
theme(plot.title = element_text(hjust = 0.5))
betas_scatter_plot
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
installr::install.R()
installr::updater()
installr::updateR()
library(MASS)
install.packages("reticulate")
install.packages("kernlab")
install.packages("Rfast")
install.packages("LaplacesDemon")
library(IsingSampler)
N = 500
reps = 100
beta = 0.2
erg = matrix(0, nrow = N, ncol = N)
p = N^{-1/3}
for(i in 1:(N-1)){
for(j in (i+1):N){
if(j>i){
erg[i,j] = erg[j,i] = rbinom(1,1, p)
}
}
}
erg = erg/(N*p) ### Erdos Renyi adjacency divided by Np, similar to Bhaswar setting
#dat = IsingSampler(1, erg, thresholds = rep(0,N), beta = 0.2,
#             responses = c(-1L,1L), method = "MH")
##### n*L_sigma(beta) ####
normeq = function(beta, sigma, A){
N = dim(A)[1]
v = rep(0, N)
for(i in 1:N){
v[i] = sum(sigma* A[i,])
}
sumand = v * (sigma - tanh(beta * v))
return(sum(sumand))
}
##### solves for root of pseudo-likelihood ####
pslkhood = function(sigma, A){
temp = uniroot(normeq, interval = c(-100,20), sigma = sigma, A = A)
return(temp$root)
}
##### non-private estimates for beta = 0.2 ####
est1 = rep(0, reps)
for(i in 1:reps){
dat = IsingSampler(n = 1, erg, thresholds = rep(0,N), beta = 0.2,
responses = c(-1L,1L), method = "MH")
est1[i] = pslkhood(dat, erg)
}
# boxplot(est1)
##### non private estimates for beta = 0.3 ####
est2 = rep(0, reps)
for(i in 1:reps){
dat = IsingSampler(n = 1, erg, thresholds = rep(0,N), beta = 3,
responses = c(-1L,1L), method = "MH")
est2[i] = pslkhood(dat, erg)
}
# install.packages("IsingSampler")
library(IsingSampler)
N = 500
reps = 100
beta = 0.2
erg = matrix(0, nrow = N, ncol = N)
p = N^{-1/3}
for(i in 1:(N-1)){
for(j in (i+1):N){
if(j>i){
erg[i,j] = erg[j,i] = rbinom(1,1, p)
}
}
}
erg = erg/(N*p) ### Erdos Renyi adjacency divided by Np, similar to Bhaswar setting
#dat = IsingSampler(1, erg, thresholds = rep(0,N), beta = 0.2,
#             responses = c(-1L,1L), method = "MH")
##### n*L_sigma(beta) ####
normeq = function(beta, sigma, A){
N = dim(A)[1]
v = rep(0, N)
for(i in 1:N){
v[i] = sum(sigma* A[i,])
}
sumand = v * (sigma - tanh(beta * v))
return(sum(sumand))
}
##### solves for root of pseudo-likelihood ####
pslkhood = function(sigma, A){
temp = uniroot(normeq, interval = c(-300,300), sigma = sigma, A = A)
return(temp$root)
}
##### non-private estimates for beta = 0.2 ####
est1 = rep(0, reps)
for(i in 1:reps){
dat = IsingSampler(n = 1, erg, thresholds = rep(0,N), beta = 0.2,
responses = c(-1L,1L), method = "MH")
est1[i] = pslkhood(dat, erg)
}
# boxplot(est1)
##### non private estimates for beta = 0.3 ####
est2 = rep(0, reps)
for(i in 1:reps){
dat = IsingSampler(n = 1, erg, thresholds = rep(0,N), beta = 3,
responses = c(-1L,1L), method = "MH")
est2[i] = pslkhood(dat, erg)
}
### non private plots part initial ####
par(mfrow = c(1,2))
boxplot(est1, xlab = "Beta = 0.2", ylab = "MPLE Estimates",
col = "skyblue")
boxplot(est2, xlab = "Beta = 3", ylab = "MPLE Estimates", col = "pink")
#### repeat experiment for grid of beta ####
betavec = seq ( from = 0 , to = 4 , length.out = 30)
mat = matrix (0 , ncol = length ( betavec ) , nrow = reps )
for ( j in 1: length ( betavec )){
for ( i in 1: reps ){
dat = IsingSampler ( n = 1 , erg , thresholds = rep (0 , N ) ,
beta = betavec [ j ] ,
responses = c ( -1L ,1L ) , method = "MH" )
mat [i , j] = pslkhood ( dat , erg )
}
print(j)
}
source("~/.active-rstudio-document", echo=TRUE)
heatmap(val)
head(vals)
head(val)
unique(val
)
install.packages("plotly")
library(plotly)
plot_ly(z = val, type = "heatmap")
plot_ly(z = val, colorscale = "Greys", type = "heatmap")
heatmap(val, labRow = F)
K3.reg.W <- function(x,y){
# INPUT: x <- first coordinate
#        y <- second coordinate
# OUTPUT: the value of the graphon
if ((0.5 < x & x <= 2/3) & (0 <= y & y <= 1/6)){
return (0.5)
}
else if ((0.5 < y & y <= 2/3) & (0 <= x & x <= 1/6)){
return (0.5)
}
else{
if ((x > 0.5) & (y > 0.5)){
x <- 1-x
y <- 1-y
}
if ((x <= 0.5) & (y <= 0.5)){
if ((x >=0 & x <= 1/6) & (y >=0 & y<=1/6)){
return (0)
}
else if ((1/6<=x & x<=1/3) & (1/6<=y & y<=1/3)){
return (0)
}
else if ((1/3<=x & x<=1/2) & (1/3<=y & y<=1/2)){
return (0)
}
else{
return (1)
}
}
else{
return (0)
}
}
}
n <- 1000
x.vals <- (1:n)/n
y.vals <- (1:n)/n
val <- matrix(0, n ,n )
for (i in 1:n){
for (j in 1:n){
val[i,j] = K3.reg.W(x.vals[i], y.vals[j])
}
}
heatmap(val, labRow = F)
library(plotly)
plot_ly(z = val, colorscale = "Greys", type = "heatmap")
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
setwd("~/Dropbox (Penn)/Kernel-Two-Sample/Revisions/Code/OVERSIGMAd300/Results")
source("~/.active-rstudio-document", echo=TRUE)
