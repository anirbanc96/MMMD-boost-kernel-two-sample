}
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
rmvpolya(1,c(0.1,0.9))
rmvpolya(2,c(0.1,0.9))
rmvpolya(1000,c(0.1,0.9))
rmvpolya(1000,c(0.1,0.9, 0.6))
#------------------------------------------------------------------------------#
#-------------------------- Common Functions ----------------------------------#
#------------------------------------------------------------------------------#
# mu0, mu1 and Sigma0, Sigma1 are global variables.
X.gen <- function(n, dim, p = 0){
# matrix for storing the samples under H0
X.samp <- matrix(0, nrow = n, ncol = dim)
choice.vec <- rbinom(n, 1, p)
for (i in 1:n){
if (choice.vec[i] == 0){
X.samp[i,] <- MASS::mvrnorm(1, mu = mu0, Sigma = Sigma0)
}
else{
#X.samp[i,] <- rmvt(1, mu = mu0, S = Sigma0, df = 10)
X.samp[i, ] <- rmvpolya(dim, alpha = wakefield::probs(dim))
}
}
return (X.samp)
}
#------------------------------------------------------------------------------#
Y.gen <- function(n, dim, p = 0){
Y.samp <- matrix(0, nrow = n, ncol = dim)
choice.vec <- rbinom(n, 1, p)
for (i in 1:n){
if (choice.vec[i] == 0){
Y.samp[i,] <- MASS::mvrnorm(1, mu = mu1, Sigma = Sigma1)
}
else{
#Y.samp[i,] <- rmvt(1, mu = mu1, S = Sigma1, df = 10)
Y.samp[i, ] <- rmvpolya(dim, alpha = wakefield::probs(dim))
}
}
return (Y.samp)
}
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
Single.MMD(n,d,p,X,Y,n.iter = 500)
Multi.MMD(n,d,p,X,Y,n.iter = 500)
source("~/Kernel Code/New1/Functions2.R", echo=TRUE)
source("~/Kernel Code/New1/Functions2.R", echo=TRUE)
power.d(100, d.seq = c(5,10,15,20,25,30,35,40,45,50), p = 0.5)
power.d <- function(n, sigma.param = 0.4, sigma.mult = 1.1,
mu.param = 0, d.seq,p = 0,
k.choice = c("GAUSS", "GEXP"), n.iter = 500){
library(foreach)
library(doParallel)
library(LaplacesDemon)
cores=detectCores()
cl <- makeCluster(cores[1]-1) #not to overload your computer
registerDoParallel(cl)
d <- d.seq
out.compare <- foreach(k=1:length(d), .combine=rbind, .export = ls(envir=globalenv())) %dopar% {
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# generating samples from distributions F and G
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,k.choice[1], n.iter)
out.row.col2 <- Multi.MMD(n, d[k], p, X, Y,k.choice[2], n.iter)
out.row <- c(out.row.col1, out.row.col2)
out.row
}
stopCluster(cl)
out.compare <- as.data.frame(out.compare)
colnames(out.compare) <- c("Single Kernel", "Single Test", "Multiple Kernel", "Multiple test")
plot.d <- plot(d,out.compare$`Single Kernel`, ty = "l", ylab = "Power", col = "red", ylim = c(0, 1)) +
lines(d, out.compare$`Multiple Kernel`, col = "blue")
return (out.compare)
}
power.d(100, d.seq = c(5,10,15,20,25,30,35,40,45,50), p = 0.5)
power.d <- function(n, sigma.param = 0.4, sigma.mult = 1.1,
mu.param = 0, d.seq,p = 0,
k.choice = c("GAUSS", "GEXP"), n.iter = 500){
library(foreach)
library(doParallel)
cores=detectCores()
cl <- makeCluster(cores[1]-1) #not to overload your computer
registerDoParallel(cl)
d <- d.seq
out.compare <- foreach(k=1:length(d), .combine=rbind, .export = ls(envir=globalenv())) %dopar% {
#----------------------------------------------------------------------------#
library(LaplacesDemon)
#----------------------------------------------------------------------------#
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# generating samples from distributions F and G
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,k.choice[1], n.iter)
out.row.col2 <- Multi.MMD(n, d[k], p, X, Y,k.choice[2], n.iter)
out.row <- c(out.row.col1, out.row.col2)
out.row
}
stopCluster(cl)
out.compare <- as.data.frame(out.compare)
colnames(out.compare) <- c("Single Kernel", "Single Test", "Multiple Kernel", "Multiple test")
plot.d <- plot(d,out.compare$`Single Kernel`, ty = "l", ylab = "Power", col = "red", ylim = c(0, 1)) +
lines(d, out.compare$`Multiple Kernel`, col = "blue")
return (out.compare)
}
power.d <- function(n, sigma.param = 0.4, sigma.mult = 1.1,
mu.param = 0, d.seq,p = 0,
k.choice = c("GAUSS", "GEXP"), n.iter = 500){
library(foreach)
library(doParallel)
cores=detectCores()
cl <- makeCluster(cores[1]-1) #not to overload your computer
registerDoParallel(cl)
d <- d.seq
out.compare <- foreach(k=1:length(d), .combine=rbind, .export = ls(envir=globalenv())) %dopar% {
#----------------------------------------------------------------------------#
library(LaplacesDemon)
#----------------------------------------------------------------------------#
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# generating samples from distributions F and G
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,k.choice[1], n.iter)
out.row.col2 <- Multi.MMD(n, d[k], p, X, Y,k.choice[2], n.iter)
out.row <- c(out.row.col1, out.row.col2)
out.row
}
stopCluster(cl)
out.compare <- as.data.frame(out.compare)
colnames(out.compare) <- c("Single Kernel", "Single Test", "Multiple Kernel", "Multiple test")
plot.d <- plot(d,out.compare$`Single Kernel`, ty = "l", ylab = "Power", col = "red", ylim = c(0, 1)) +
lines(d, out.compare$`Multiple Kernel`, col = "blue")
return (out.compare)
}
power.d(100, d.seq = c(5,10,15,20,25,30,35,40,45,50), p = 0.5)
source("~/Kernel Code/New1/Functions2.R", echo=TRUE)
power.d(100, d.seq = c(5,10,15,20,25,30,35,40,45,50), p = 0.5)
source("~/Kernel Code/New1/Functions2.R", echo=TRUE)
power.d(100, d.seq = c(5,10,15,20,25,30,35,40,45,50), p = 0.5)
power.d(100, d.seq = c(5,10), p = 0.5)
sigma.param = 0.4, sigma.mult = 1.1,
mu.param = 0, d.seq,p = 0,
kernel.choice
sigma.param <- 0.4
sigma.param <- 0.4
sigma.mult <- 1.1
mu.param <- 0
d <- c(5,10)
kernel.choice = c("GAUSS", "GEXP")
p <- 0.5
n.iter = 500
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
k <- 1
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
# generating samples from distributions F and G
X <- X.gen(n, d, p)
Y <- Y.gen(n, d, p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,kernel.choice[1], n.iter)
warnings()
out.row.col2 <- Multi.MMD(n, d[k], p, X, Y,kernel.choice[2], n.iter)
warnings()
k <- 2
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
# generating samples from distributions F and G
X <- X.gen(n, d, p)
# generating samples from distributions F and G
X <- X.gen(n, d[k], p)
Y <- Y.gen(n, d[k], p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,kernel.choice[1], n.iter)
source("~/Kernel Code/New1/Functions2.R", echo=TRUE)
power.d(100,d.seq = c(5,10), p = 0.5)
power.d(200,d.seq = 5*(1:10), p = 0.5)
power.d(200,d.seq = c(5,10*(1:12)), p = 0.5)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Body.R", echo=TRUE)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
#source("Functions.R")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
# Number of data points
n <- 100
# Dimension vector of data
d <- c(5,10)
# probability of mixture
p <- 0.5
# parameter for sigma0 matrix generation
sigma.param <- 0.4
# parameter for sigma1 = c*sigma0 matrix generation
sigma.mult <- 1.1
# parameter for mean value for H1 distribution
mu.param <- 0
# 1st coordinate for single, 2nd for multiple
kernel.choice <- c("GAUSS", "GEXP")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
out.d <- power.d(n, sigma.param = sigma.param, sigma.mult = sigma.mult,
mu.param = mu.param, d.seq = d, p = p,
kernel.choice = kernel.choice)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
#source("Functions.R")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
# Number of data points
n <- 100
# Dimension vector of data
d <- c(5,10)
# probability of mixture
p <- 0.5
# parameter for sigma0 matrix generation
sigma.param <- 0.4
# parameter for sigma1 = c*sigma0 matrix generation
sigma.mult <- 1.1
# parameter for mean value for H1 distribution
mu.param <- 0
# 1st coordinate for single, 2nd for multiple
kernel.choice <- c("GAUSS", "GEXP")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
out.d <- power.d(n, sigma.param = sigma.param, sigma.mult = sigma.mult,
mu.param = mu.param, d.seq = d, p = p,
kernel.choice = kernel.choice)
out.d
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Functions.R", echo=TRUE)
source("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Code/Mixture distribution/Body.R", echo=TRUE)
source("~/Kernel Code/Try1.R", echo=TRUE)
start <- Sys.time()
# Number of repetitions
n.rep <- 1
# Number of data points
n <- 100
# Dimension vector of data
d <- c(5,10*c(1:10))
# probability of mixture
p <- 0
# parameter for sigma0 matrix generation
sigma.param <- 0.4
# parameter for sigma1 = c*sigma0 matrix generation
sigma.mult <- 1
# parameter for mean value for H1 distribution
mu.param <- 0.1
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
# Choice of kernel for single and multiple kernel tests
# poissble choices:
# single - "GAUSS" or "LAP" for gaussian or laplacian
# multiple - "MINMAX", "GEXP" or "MIXED" for gaussian kernel with min-max,
# exponential bandwidth choice, or mixture of gaussian and laplace kernel.
# 1st coordinate for single, 2nd for multiple
kernel.choice <- c("GAUSS", "MIXED")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
out.d <- c()
for (iter in 1:n.rep){
out.d.iter <- power.d(n, sigma.param = sigma.param, sigma.mult = sigma.mult,
mu.param = mu.param, d.seq = d, p = p,
kernel.choice = kernel.choice)
out.d <- c(out.d, out.d.iter)
print (iter)
}
out.d <- as.matrix(as.data.frame(out.d))
end <- Sys.time()
end-start
k <- 5
d
# Number of data points
n <- 100
# Dimension vector of data
d <- c(5,10*c(1:10))
# probability of mixture
p <- 0
# parameter for sigma0 matrix generation
sigma.param <- 0.4
# parameter for sigma1 = c*sigma0 matrix generation
sigma.mult <- 1
# parameter for mean value for H1 distribution
mu.param <- 0.1
# 1st coordinate for single, 2nd for multiple
kernel.choice <- c("GAUSS", "MIXED")
k
n.iter <- 500
print (2)
1+1
#----------------------------------------------------------------------------#
library(LaplacesDemon)
library(Rfast)
sink("log.txt", append=TRUE)
# Sigma0 matrix <- cov matrix under H0
Sigma0 <- matrix(0, nrow = d[k], ncol = d[k])
for(i in 1:d[k]){
for(j in 1:d[k]){
Sigma0[i,j] = sigma.param^(abs(i-j))
}
}
# cov matrix under H0
Sigma1 <- sigma.mult*Sigma0
#----------------------------------------------------------------------------#
#----------------------------------------------------------------------------#
# mean vector under H0
mu0 <- rep(0, d[k])
# mean vector under H1
mu1 <- rep(mu.param, d[k])
# generating samples from distributions F and G
X <- X.gen(n, d[k], p)
Y <- Y.gen(n, d[k], p)
out.row.col1 <- Single.MMD(n, d[k], p, X, Y,kernel.choice[1], n.iter)
out.row.col2 <- Multi.MMD(n, d[k], p, X, Y,kernel.choice[2], n.iter)
n.rep <- 1
# Number of data points
n <- 100
# Dimension vector of data
d <- c(5,10*c(1:10))
# probability of mixture
p <- 0
# parameter for sigma0 matrix generation
sigma.param <- 0.4
# parameter for sigma1 = c*sigma0 matrix generation
sigma.mult <- 1
# parameter for mean value for H1 distribution
mu.param <- 0.1
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
# Choice of kernel for single and multiple kernel tests
# poissble choices:
# single - "GAUSS" or "LAP" for gaussian or laplacian
# multiple - "MINMAX", "GEXP" or "MIXED" for gaussian kernel with min-max,
# exponential bandwidth choice, or mixture of gaussian and laplace kernel.
# 1st coordinate for single, 2nd for multiple
kernel.choice <- c("GAUSS", "MIXED")
#------------------------------------------------------------------------------#
#------------------------------------------------------------------------------#
out.d <- c()
for (iter in 1:n.rep){
out.d.iter <- power.d(n, sigma.param = sigma.param, sigma.mult = sigma.mult,
mu.param = mu.param, d.seq = d, p = p,
kernel.choice = kernel.choice)
out.d <- c(out.d, out.d.iter)
print (iter)
}
out.d <- as.matrix(as.data.frame(out.d))
end <- Sys.time()
end-start
setwd("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Data/MNIST-Reduced Contrast and AGWN")
source("~/.active-rstudio-document", echo=TRUE)
library(rmatio)
mnist.list <- read.mat("mnist-with-reduced-contrast-and-awgn.mat")
train.x <- mnist.list$train_x/255
train.y.mat <- mnist.list$train_y
train.label <- rep(NA,dim(train.y.mat)[1])
for(i in 1:dim(train.y.mat)[1]){
train.label[i] <- which(train.y.mat[i,] == 1)-1
}
set.choice <- vector("list", 5)
set.choice[[1]] <- rbind(c(2,4,8,9), c(3,4,7,9))
set.choice[[2]] <- rbind(c(1,2,4,8,9), c(1,3,4,7,9))
set.choice[[3]] <- rbind(c(0,1,2,4,8,9), c(0,1,3,4,7,9))
set.choice[[4]] <- rbind(c(0,1,2,4,5,8,9), c(0,1,3,4,5,7,9))
set.choice[[5]] <- rbind(c(0,1,2,4,5,6,8,9), c(0,1,3,4,5,6,7,9))
start <- Sys.time()
n.rep <- 30
resamp <- 150
remove(mnist.list)
out.d <- c()
for (iter in 1:n.rep){
# storing power values for particular iteration
out.d.iter <- power.d(resamp, set.choice,
n.iter = 500)
out.d <- c(out.d, out.d.iter)
print (iter)
}
out.d <- as.matrix(as.data.frame(out.d))
end <- Sys.time()
end-start
single.FR.d1 <- 2+3*(0:(n.rep-1))
single.GE.d2 <- 3*(1:(n.rep))
power.FR.mat1 <- matrix(0, nrow = length(set.choice), ncol = n.rep)
power.GE.mat2 <- matrix(0, nrow = length(set.choice), ncol = n.rep)
for (k in 1:length(set.choice)){
power.FR.mat1[k,] <- out.d[k,single.FR.d1]
power.GE.mat2[k,] <- out.d[k,single.GE.d2]
}
power.FR.mat1 <- cbind(set.choice,power.FR.mat1)
power.GE.mat2 <- cbind(set.choice,power.GE.mat2)
setwd("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Data/MNIST-Reduced Contrast and AGWN/Results")
write.csv(power.FR.mat1, file = "Power-FR.csv")
library(tidyverse)
# read the power values
multi1 <- read_csv("MultiPower-LAP.csv")[,-c(1,2)]
multi2 <- read_csv("MultiPower-GEXP.csv")[,-c(1,2)]
multi3 <- read_csv("MultiPower-MIXED.csv")[,-c(1,2)]
single1 <- read_csv("SinglePower-LAP.csv")[,-c(1,2)]
single2 <- read_csv("SinglePower-GAUSS.csv")[,-c(1,2)]
FR <- read_csv("Power-FR.csv")[,-c(1,2)]
# mean of power values
multi1.mean <- apply(multi1, 1, mean)
multi2.mean <- apply(multi2, 1, mean)
multi3.mean <- apply(multi3, 1, mean)
single1.mean <- apply(single1, 1, mean)
single2.mean <- apply(single2, 1, mean)
FR.mean <- apply(FR, 1, mean)
d <- (read_csv("MultiPower-GEXP.csv")[2])%>%pull(1)
power.tibble <- tibble(power = c(single1.mean,single2.mean, multi1.mean,
multi2.mean, multi3.mean, FR.mean),
dim = c(d,d,d,d,d,d),
group = c(rep("Single Laplace Kernel", length(d)),
rep("Single Gaussian Kernel", length(d)),
rep("Multiple Laplace Kernels", length(d)),
rep("Multiple Gaussian Kernels", length(d)),
rep("Multiple Mixed Kernels", length(d)),
rep("Friedman Rafsky", length(d))))
# plotting the power along with sd
(power.plot <- power.tibble %>%
ggplot(aes(x = dim, y = power, group = group, col = group, fill = group)) +
geom_point(size = 2) +
geom_line(size = 1) +
#geom_ribbon(aes(ymin = low, ymax = up), alpha = 0.3, linetype = 0)+
labs(x = "Set Choice", y = "Estimated Power", color = "Test", fill = "Test") +
theme_bw()
)
power.FR.mat1
d
power.FR.mat1[,1] <- c(1:5)
power.FR.mat1
write.csv(power.FR.mat1, file = "Power-FR.csv")
FR.mean
setwd("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Data/MNIST-Reduced Contrast and AGWN")
setwd("C:/Users/anirbanc/Dropbox (Penn)/Kernel-Two-Sample/Data/MNIST-Reduced Contrast and AGWN/Code")
write.csv(power.FR.mat1, file = "Power-FR.csv")
